{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "refined-praise",
   "metadata": {},
   "source": [
    "# Working on Big-Data using Pyspark:\n",
    " *Created by Anmol Kumar [May 11 2022]*\n",
    "\n",
    "### Libraries required:\n",
    "* Pandas, PySpark. To view instructions on installing them, visit [Pandas](https://pandas.pydata.org/) and [PySpark](https://spark.apache.org/docs/latest/api/python/index.html).\n",
    "* In addition to this, Java is also required. Visit [Java](https://www.java.com/en/) for instructions.\n",
    "\n",
    "### Process followed:\n",
    "* Reading the csv file using SparkSession object. Since the file is ~1.38GB, Pandas cannot be used.\n",
    "\n",
    "##### Task 1:\n",
    "* To get the products which don't have a price, I have used ``pyspark.sql.Column.isNull`` to filter the rows with ``price_string`` as ``null``.\n",
    "\n",
    "##### Task 2:\n",
    "* To count of products without prices and with prices in each Product Type, Category, Level 1, I first removed the duplicates in each type of product.\n",
    "* After getting a DataFrame of each unique type, I extracted all the unique values in a list.\n",
    "* After that, I iterated over each item in the list to separately obtain two new DataFrames having prices and not having prices\n",
    "* ``pyspark.sql.DataFrame.count`` is then used to get the required number.\n",
    "\n",
    "##### Task 3:\n",
    "* Using ``pyspark.sql.DataFrame.filter``, ``pyspark.sql.Column.isNotNull``, ``pyspark.sql.Column.startswith`` and ``pyspark.sql.Column.substr``, we can process in the following sequential way.\n",
    "* I first look for the entries which have workable ``price_string``, i.e., non-``null`` values.\n",
    "* After that I only look for the entries which begin with dollar sign to extract their values.\n",
    "* I then extract the values and arrange them separately in ``values`` Column.\n",
    "\n",
    "##### Task 4:\n",
    "* Iterating over every category, we can use ``pyspark.sql.DataFrame.agg`` to get average prices in every category.\n",
    "\n",
    "### How to run the notebook?\n",
    "* Make sure the required libraries and Python are installed.\n",
    "* Next, make sure the ``data_values.csv`` is present in the same directory as the notebook.\n",
    "* Open a terminal in the directory and run the notebook. For notebook, visit [Jupyter Notebook](https://jupyter.org/) or any other notebook installation websites for further instructions.\n",
    "* In case of Jupyter, open the notebook and click on 'Cell', then 'Run All'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "mounted-comparison",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark=SparkSession.builder.appName(\"pysparkdf\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "coral-lending",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+----------------+--------------------+--------------------+--------------------+\n",
      "|                uuid|price_string|price_string_unf|        product_type|             level_1|            category|\n",
      "+--------------------+------------+----------------+--------------------+--------------------+--------------------+\n",
      "|638744a4-b0ae-416...|        null|            null|TGFwdG9wIENvdmVyc...|     TGFwdG9wIENhc2U|     RWxlY3Ryb25pY3M|\n",
      "|ab313969-02cc-48b...|        null|            null|QmFraW5nIEN1cHMgY...|QmFraW5nIE1hdHMgL...|a2l0Y2hpbmcgYW5kI...|\n",
      "|acbd66ff-79f8-467...|      $19.95|            null|R3VtbWllcyB2aXRhb...|SW1tdW5pdHkgZ3Vtb...|            SGVhbHRo|\n",
      "|963915d6-b2e3-409...|      $92.00|            null|            U2VydW1z|      RmFjZSBTZXJ1bQ|YmVhdXR5IGFuZCBwZ...|\n",
      "|b5b68f3c-b1e0-40e...|       11.50|            null|RWF0aW5nIFV0ZW5za...|      Q2hvcHN0aWNrcw|a2l0Y2hpbmcgYW5kI...|\n",
      "|389d9f75-cc3f-4bd...|        null|            null|TmF0dXJhbCBTd2Vld...|      TW9uayBGcnVpdA|        Z3JvY2VyaWVz|\n",
      "|9599f1a9-d406-43e...|      $24.99|            null|TW9wcyBhbmQgYnJvb21z|                TW9w|SG91c2Vob2xkIGFuZ...|\n",
      "|35799087-f6f4-4ca...|     $148.00|            null|    V29tZW5zIFBhbnRz|V29tZW5zIFJlZ3VsY...|Q2xvdGhpbmcgYW5kI...|\n",
      "|9b3f553e-ee4c-4e1...|         $89|            null|    V29tZW5zIFBhbnRz|  V29tZW5zIFRpZ2h0cw|Q2xvdGhpbmcgYW5kI...|\n",
      "|6871b427-3c2c-4b3...|      $14.95|            null|     Um9sbGluZyBQaW4|UGxheSBEb3VnaCBSb...| VG95cyBhbmQgR2FtZXM|\n",
      "+--------------------+------------+----------------+--------------------+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.option(\"header\", \"true\").csv(\"data-values.csv\")\n",
    "\n",
    "#Checking the top 10 rows\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "constitutional-honor",
   "metadata": {},
   "source": [
    "##### Task 1:\n",
    "* To get the products which don't have a price, I will use ``pyspark.sql.Column.isNull`` to filter the rows with ``price_string`` as ``null``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aggregate-watts",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+----------------+--------------------+--------------------+--------------------+\n",
      "|                uuid|price_string|price_string_unf|        product_type|             level_1|            category|\n",
      "+--------------------+------------+----------------+--------------------+--------------------+--------------------+\n",
      "|638744a4-b0ae-416...|        null|            null|TGFwdG9wIENvdmVyc...|     TGFwdG9wIENhc2U|     RWxlY3Ryb25pY3M|\n",
      "|ab313969-02cc-48b...|        null|            null|QmFraW5nIEN1cHMgY...|QmFraW5nIE1hdHMgL...|a2l0Y2hpbmcgYW5kI...|\n",
      "|389d9f75-cc3f-4bd...|        null|            null|TmF0dXJhbCBTd2Vld...|      TW9uayBGcnVpdA|        Z3JvY2VyaWVz|\n",
      "|1f2766ec-0a27-43f...|        null|            null|U2NydWJzIGFuZCBjb...|            U2NydWJz|SG91c2Vob2xkIGFuZ...|\n",
      "|7bad39f5-74b9-461...|        null|            null|UGx1cyBzaXplIHdlY...|             RHJlc3M|Q2xvdGhpbmcgYW5kI...|\n",
      "|524886b5-7cc2-4a5...|        null|            null| TWF0ZXJuaXR5IFBhZHM|UG9zdHBhcnR1bSBQYWRz|YmVhdXR5IGFuZCBwZ...|\n",
      "|ae346b86-21ff-431...|        null|            null|RWR1Y2F0aW9uYWwgQ...|     TnVtYmVyIFRveXM| VG95cyBhbmQgR2FtZXM|\n",
      "|cc3dd359-7aa9-414...|        null|            null|UGxhbnQgYmFzZWQgU...|S2V0byBEaWV0IFdla...|            SGVhbHRo|\n",
      "|327e1b21-5ba7-464...|        null|            null|Q2FuZGxlcy9GcmFnb...|          Q2FuZGxlcw|SG91c2Vob2xkIGFuZ...|\n",
      "|9e740140-648a-497...|        null|            null|bWVucyBCb2R5IFNvY...|  bWVucyBCb2R5d2FzaA|YmVhdXR5IGFuZCBwZ...|\n",
      "+--------------------+------------+----------------+--------------------+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#To get products without prices\n",
    "df_task1 = df.where(df['price_string'].isNull())\n",
    "\n",
    "#Checking the top 10 rows to see if it works\n",
    "df_task1.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "timely-brazilian",
   "metadata": {},
   "source": [
    "##### Task 2:\n",
    "* To count of products without prices and with prices in each Product Type, Category, Level 1, I first removed the duplicates in each type of product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sublime-applicant",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c = df.drop_duplicates(subset = ['category'])\n",
    "df_p = df.drop_duplicates(subset = ['product_type'])\n",
    "df_l = df.drop_duplicates(subset = ['level_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "classical-conclusion",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+----------------+--------------------+--------------------+--------------------+\n",
      "|                uuid|price_string|price_string_unf|        product_type|             level_1|            category|\n",
      "+--------------------+------------+----------------+--------------------+--------------------+--------------------+\n",
      "|13724827-979f-401...|        null| Current price: |                null|                null|                null|\n",
      "|8e598c24-db06-48d...|         $75|            null|V2ludGVyIEFjY2Vzc...|            QmVhbmll|Q2xvdGhpbmcgYW5kI...|\n",
      "|778768c3-7c21-44a...|       $6.50|            null|TmF0dXJhbCBQaWdtZ...|TmF0dXJhbCBQaWdtZ...|    QXJ0IHN1cHBsaWVz|\n",
      "|07941b4b-2995-488...|        null|            null|        QmFieSBUb3lz|     RmFicmljIHRveXM|         QmFieWNhcmU|\n",
      "|a571890c-4c5d-4c9...|      $24.95|            null|U21hcnQgV2F0Y2ggU...|U21hcnQgV2F0Y2ggU...|     RWxlY3Ryb25pY3M|\n",
      "|9599f1a9-d406-43e...|      $24.99|            null|TW9wcyBhbmQgYnJvb21z|                TW9w|SG91c2Vob2xkIGFuZ...|\n",
      "|1840ff21-aa38-437...|      $32.99|            null|UGxhbnQgYmFzZWQgU...|UGxhbnQgYmFzZWQgc...|            SGVhbHRo|\n",
      "|6871b427-3c2c-4b3...|      $14.95|            null|     Um9sbGluZyBQaW4|UGxheSBEb3VnaCBSb...| VG95cyBhbmQgR2FtZXM|\n",
      "|cf5a39b7-65a3-421...|        null|            null|S2l0Y2hlbiBTaW5rI...|VHdvIEhhbmRsZSBGY...|VG9vbHMgYW5kIGhvb...|\n",
      "|963915d6-b2e3-409...|      $92.00|            null|            U2VydW1z|      RmFjZSBTZXJ1bQ|YmVhdXR5IGFuZCBwZ...|\n",
      "+--------------------+------------+----------------+--------------------+--------------------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Checking the first 10 rows of unique category DataFrame. Product_type and level_1 will execute in the same way\n",
    "df_c.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "uniform-start",
   "metadata": {},
   "source": [
    "* Extracted all the unique values as a list.\n",
    "* ``pyspark.sql.DataFrame.count`` is then used to get the required number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "earlier-emergency",
   "metadata": {},
   "outputs": [],
   "source": [
    "cats = [row['category'] for row in df_c.collect()]\n",
    "prod_types = [row['product_type'] for row in df_p.collect()]\n",
    "levels = [row['level_1'] for row in df_l.collect()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "electoral-dealer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat:  None , with prices:  0 , without prices: 0\n",
      "cat:  Q2xvdGhpbmcgYW5kIEFjY2Vzc29yaWVz , with prices:  2030000 , without prices: 1840000\n",
      "cat:  QXJ0IHN1cHBsaWVz , with prices:  130000 , without prices: 190000\n",
      "cat:  QmFieWNhcmU , with prices:  550000 , without prices: 90000\n",
      "cat:  RWxlY3Ryb25pY3M , with prices:  210000 , without prices: 110000\n",
      "cat:  SG91c2Vob2xkIGFuZCBDbGVhbmluZw , with prices:  870000 , without prices: 700000\n",
      "cat:  SGVhbHRo , with prices:  700000 , without prices: 290000\n",
      "cat:  VG95cyBhbmQgR2FtZXM , with prices:  600000 , without prices: 190000\n",
      "cat:  VG9vbHMgYW5kIGhvbWUgaW1wcm92ZW1lbnQ , with prices:  320000 , without prices: 200000\n",
      "cat:  YmVhdXR5IGFuZCBwZXJzb25hbCBjYXJl , with prices:  720000 , without prices: 750000\n"
     ]
    }
   ],
   "source": [
    "# Finding the number of products with prices and without prices in the first 5 types of value in categories\n",
    "for cat in cats[0:10]:\n",
    "    df_or = df.filter(df['category'] == cat)\n",
    "    count_full = df_or.count()\n",
    "    count_none = df_or.na.drop(subset = 'price_string').count()\n",
    "    print('cat: ', cat,', with prices: ', (count_full-count_none),', without prices:', count_none)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "rolled-spencer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prod_type:  None , with prices:  0 , without prices: 0\n",
      "prod_type:  Q0FUIExJVFRFUg , with prices:  30000 , without prices: 0\n",
      "prod_type:  Q29mZmVlIEJlYW5z , with prices:  50000 , without prices: 30000\n",
      "prod_type:  Q29mZmVlIEZpbHRlcnM , with prices:  10000 , without prices: 0\n",
      "prod_type:  Q29uZGl0aW9uZXIgSGFpcg , with prices:  20000 , without prices: 10000\n",
      "prod_type:  Q29va2llcw , with prices:  30000 , without prices: 0\n",
      "prod_type:  Q29va2luZyBPaWw , with prices:  10000 , without prices: 70000\n",
      "prod_type:  Q29va2luZyBVdGVuc2lscw , with prices:  20000 , without prices: 110000\n",
      "prod_type:  Q2F0IHRveXMgcGV0 , with prices:  20000 , without prices: 0\n",
      "prod_type:  Q2FuZGxlcy9GcmFnbmFuY2Vz , with prices:  20000 , without prices: 40000\n"
     ]
    }
   ],
   "source": [
    "# Finding the number of products with prices and without prices in the first 5 types of value in product_type\n",
    "for prod in prod_types[0:10]:\n",
    "    df_or = df.filter(df['product_type'] == prod)\n",
    "    count_full = df_or.count()\n",
    "    count_none = df_or.na.drop(subset = 'price_string').count()\n",
    "    print('prod_type: ', prod,', with prices: ', (count_full-count_none),', without prices:', count_none)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "attended-sunglasses",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level:  None , with prices:  0 , without prices: 0\n",
      "level:  MTAgQ3Vw , with prices:  0 , without prices: 10000\n",
      "level:  MjAgQ3Vw , with prices:  0 , without prices: 10000\n",
      "level:  MjAgUGludHM , with prices:  20000 , without prices: 10000\n",
      "level:  MzAgQ3Vw , with prices:  0 , without prices: 10000\n",
      "level:  MzAtIDM1IFBpbnRz , with prices:  10000 , without prices: 10000\n",
      "level:  NSBHYWxsb24 , with prices:  0 , without prices: 10000\n",
      "level:  NTAgUGludHM , with prices:  20000 , without prices: 10000\n",
      "level:  NiBDdXA , with prices:  0 , without prices: 10000\n",
      "level:  OCBDdXA , with prices:  0 , without prices: 10000\n"
     ]
    }
   ],
   "source": [
    "# Finding the number of products with prices and without prices in the first 5 types of value in level_1\n",
    "for level in levels[0:10]:\n",
    "    df_or = df.filter(df['level_1'] == level)\n",
    "    count_full = df_or.count()\n",
    "    count_none = df_or.na.drop(subset = 'price_string').count()\n",
    "    print('level: ', level,', with prices: ', (count_full-count_none),', without prices:', count_none)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "equivalent-congo",
   "metadata": {},
   "source": [
    "##### Task 3:\n",
    "* the first ``filter`` is used to filter the products with ``null`` as ``price_string``.\n",
    "* the second ``filter`` finds the products whose prices begin with dollar sign, as only they can be extracted into the new required columns.\n",
    "* ``select`` is used to generate a new DataFrame with the same columns as the original DataFrame but with new ``currency`` and ``value``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "upper-remedy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------------+----------------+--------------------+--------------------+--------------------+--------+-----+\n",
      "|                uuid|price_string|price_string_unf|        product_type|             level_1|            category|currency|value|\n",
      "+--------------------+------------+----------------+--------------------+--------------------+--------------------+--------+-----+\n",
      "|acbd66ff-79f8-467...|      $19.95|            null|R3VtbWllcyB2aXRhb...|SW1tdW5pdHkgZ3Vtb...|            SGVhbHRo|       $|19.95|\n",
      "|963915d6-b2e3-409...|      $92.00|            null|            U2VydW1z|      RmFjZSBTZXJ1bQ|YmVhdXR5IGFuZCBwZ...|       $|92.00|\n",
      "|9599f1a9-d406-43e...|      $24.99|            null|TW9wcyBhbmQgYnJvb21z|                TW9w|SG91c2Vob2xkIGFuZ...|       $|24.99|\n",
      "|35799087-f6f4-4ca...|     $148.00|            null|    V29tZW5zIFBhbnRz|V29tZW5zIFJlZ3VsY...|Q2xvdGhpbmcgYW5kI...|       $|148.0|\n",
      "|9b3f553e-ee4c-4e1...|         $89|            null|    V29tZW5zIFBhbnRz|  V29tZW5zIFRpZ2h0cw|Q2xvdGhpbmcgYW5kI...|       $|   89|\n",
      "|6871b427-3c2c-4b3...|      $14.95|            null|     Um9sbGluZyBQaW4|UGxheSBEb3VnaCBSb...| VG95cyBhbmQgR2FtZXM|       $|14.95|\n",
      "|bc4a0598-1910-481...|      $55.00|            null|      Q2FyZHN0b2Nrcw|             Q2FyZHM|    QXJ0IHN1cHBsaWVz|       $|55.00|\n",
      "|963915d6-b2e3-409...|      $92.00|            null|            U2VydW1z|      RmFjZSBTZXJ1bQ|YmVhdXR5IGFuZCBwZ...|       $|92.00|\n",
      "|b332aedb-005f-4af...|      $11.30|            null|UGxhdGVzL1V0ZW5za...|            UGxhdGVz|a2l0Y2hpbmcgYW5kI...|       $|11.30|\n",
      "|da7f0d13-ec69-4f1...|      $13.99|            null| TnV0cyAtIENhc2hld3M|          Q2FzaGV3cw|        Z3JvY2VyaWVz|       $|13.99|\n",
      "+--------------------+------------+----------------+--------------------+--------------------+--------------------+--------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Importing the required function to fill the currency column\n",
    "from pyspark.sql.functions import lit\n",
    "\n",
    "df_task3 = df.filter(df['price_string'].isNotNull()).filter(df['price_string'].startswith('$')).select(df[0], df[1], df[2], df[3], df[4], df[5], lit('$').alias('currency'), df['price_string'].substr(2,5).alias('value'))\n",
    "\n",
    "#Checking the top 10 rows to see if it works\n",
    "df_task3.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "private-tongue",
   "metadata": {},
   "source": [
    "##### Task 4:\n",
    "* Iterate over each category and use ``pyspark.sql.DataFrame.agg`` to get average prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "early-arrest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat:  Q2xvdGhpbmcgYW5kIEFjY2Vzc29yaWVz , average price:  125.24032786885073\n",
      "cat:  QXJ0IHN1cHBsaWVz , average price:  19.467368421053862\n",
      "cat:  QmFieWNhcmU , average price:  163.67888888888473\n",
      "cat:  RWxlY3Ryb25pY3M , average price:  60.25000000000101\n",
      "cat:  SG91c2Vob2xkIGFuZCBDbGVhbmluZw , average price:  75.73811594210714\n",
      "cat:  SGVhbHRo , average price:  32.55758620688889\n",
      "cat:  VG95cyBhbmQgR2FtZXM , average price:  37.115333333335165\n",
      "cat:  VG9vbHMgYW5kIGhvbWUgaW1wcm92ZW1lbnQ , average price:  82.20799999999528\n",
      "cat:  YmVhdXR5IGFuZCBwZXJzb25hbCBjYXJl , average price:  34.745066666667455\n",
      "cat:  Z3JvY2VyaWVz , average price:  10.541666666662943\n"
     ]
    }
   ],
   "source": [
    "#Going through the first 5 categories with 0 excluded as its a None values\n",
    "for cat in cats[1:11]:\n",
    "    df_temp = df_task3.filter(df_task3['category'] == cat)\n",
    "    avg = df_temp.agg({'value': 'avg'})\n",
    "    avg_val = avg.head()[0]\n",
    "    print('cat: ', cat, ', average price: ', avg_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compatible-cartoon",
   "metadata": {},
   "source": [
    "### Remarks:\n",
    "* I have used the first 10 values in most of the examples but they can be iterated throughout the entire DataFrame without any errors. Although it will consume a lot more time to execute."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
